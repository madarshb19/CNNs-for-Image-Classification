{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madarshb19/CNNs-for-Image-Classification/blob/main/CNNsForCatsAndDogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator   #helps in preprocessing images"
      ],
      "metadata": {
        "id": "dIPQpDGOmDg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AW0Teqtuma21",
        "outputId": "20197ae2-7da3-4563-b0bd-da023d2c0489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset consists of images,data preprocessing would look different"
      ],
      "metadata": {
        "id": "-oBDDWRul6K9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we apply transformation on training sets to avoid overfitting (this is also done in a general computervision problem)\n",
        "#this is called image augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,  #applies feature scaling to every pixel\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        'dataset/training_set',\n",
        "        target_size=(64, 64), #size of images (changed from 150 to 64 for faster computation)\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "id": "fsE_GJ4Dmof1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255) #transformation is not done on test set,only feature scaling is performed\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'dataset/test_set',\n",
        "        target_size=(64,64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "id": "kVjubj_F0dRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "vREOJ0_v1htR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3,activation = 'relu',input_shape = [64,64,3])) #number of filters can be experimented,kernel size/feature detector = 3*3 which is most used,input shape = 64*64 layer. for rgb 64 64 3,for b/w 64 64 1"
      ],
      "metadata": {
        "id": "f9uRNf8a10gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2,strides = 2))"
      ],
      "metadata": {
        "id": "rEJOLODK3T1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3,activation = 'relu')) #input shape parameter is only to connect the first input layer\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2,strides = 2))"
      ],
      "metadata": {
        "id": "VTtqBd644Vwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "VyebW1UW4i7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units= 128,activation = 'relu')) #no of units can also be experimented"
      ],
      "metadata": {
        "id": "JPC_ZYxG5HDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units= 1,activation = 'sigmoid')) #for binary,units = 1"
      ],
      "metadata": {
        "id": "YSVp_uLC5IIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "YeGVTnXX6LNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set,validation_data = test_set,batch_size = 32,epochs = 25)"
      ],
      "metadata": {
        "id": "JX08so4x61D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img(\n",
        "    'dataset/single_prediction/cat_or_dog_1.jpg',\n",
        "    target_size = (64,64)   #converting given image to 64*64 for training\n",
        ")\n",
        "test_image = image.img_to_array(test_image)\n",
        "#while training the network,there was an additional dimension of batch size = 32 so we need to add this batch dimension below\n",
        "test_image = np.expand_dims(test_image,axis = 0)\n",
        "result = cnn.predict(test_image) #result will return 0 or 1,now we have to find which is 0 and which is 1\n",
        "training_set.class_indices #this gives the corresponding binary class\n",
        "if(result[0][0] == 1):\n",
        "  prediction = 'Prediction : Dog'\n",
        "else:\n",
        "  prediction = 'Prediction : Cat'"
      ],
      "metadata": {
        "id": "3acgs8VA72BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "id": "p8PdYiNn_yh0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}